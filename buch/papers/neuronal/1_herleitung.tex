%
% 1_herleitung.tex -- Herleitung der Methode
%
% (c) 2025 Roman Cvijanovic & Nicola Dall'Acqua, Hochschule Rapperswil
%
% !TEX root = ../../buch.tex
% !TEX encoding = UTF-8
%

\section{Herleitung der Methode\label{neuronal:section:herleitung}}
\kopfrechts{Herleitung der Methode}

Im Folgenden wird die Methode zur Lösung von Feldgleichungen mittels eines neuronalen Netzes theoretisch hergeleitet.
Zunächst wird eine allgemeine Form für Feldgleichungen bzw. partielle Differentialgleichungen benötigt.
Die allgemeine Form einer Feldgleichung lautet:
\begin{equation}
\mathcal{D}(\varphi(x, t)) = 0 \qquad x \in \Omega, \quad t \in [0,T]
\label{neuronal:generelle_feldgleichung}
\end{equation}
Dabei gilt die Randbedingung:
\begin{equation}
\varphi(x, t) = 0 \qquad x \in \partial \Omega, \quad t \in [0,T]
\end{equation}
sowie die Anfangsbedingungen:
\begin{equation}
    \begin{aligned}
        \varphi(x, t = 0) &= f(x) \qquad x \in \Omega \\
        \partial_t \varphi(x, t = 0) &= g(x) \qquad x \in \Omega.
    \end{aligned}
\end{equation}
Hierbei ist:
\begin{itemize}
    \item $\varphi(x, t)$ das gesuchte Feld,
    \item $\mathcal{D}$ ein beliebiger Differentialoperator auf $\varphi$,
    \item $f(x)$ und $g(x)$ bekannte Funktionen, die die Anfangsbedingungen definieren,
    \item $\Omega$ der Bereich, in dem das Feld definiert ist,
    \item $\partial \Omega$ der Rand des Feldes,
    \item $[0,T]$ das betrachtete Zeitintervall.
\end{itemize}

Die Randbedingung legt fest, wie sich das Feld $\varphi(x, t)$ am Rand des Bereichs $\Omega$ verhält.
In diesem Fall wird angenommen, dass das Feld am Rand verschwindet, was bedeutet, dass $\varphi(x, t) = 0$ für alle $x$ auf dem Rand $\partial \Omega$ und für alle Zeiten $t$ im Intervall $[0,T]$ gilt.
Randbedingungen sind entscheidend, um die Lösung der Feldgleichung eindeutig zu machen, da sie die Werte des Feldes an den Grenzen des Definitionsbereichs festlegen.


Die Anfangsbedingungen beschreiben den Zustand des Feldes zu Beginn des betrachteten Zeitintervalls.
Die erste Anfangsbedingung, $\varphi(x, t = 0) = f(x)$, gibt die Verteilung des Feldes zum Zeitpunkt $t = 0$ an.
Die zweite Anfangsbedingung, $\partial_t \varphi(x, t = 0) = g(x)$, beschreibt die zeitliche Änderung des Feldes zum Zeitpunkt $t = 0$.
Diese Bedingungen sind notwendig, um die Dynamik des Feldes über die Zeit hinweg zu bestimmen.

Als Beispiel für den Differentialoperator $\mathcal{D}$ kann dieser wie folgt aussehen:
\begin{equation*}
    \mathcal{D}(\varphi(x, y, t)) = \frac{\partial^2 \varphi}{\partial t^2} - c^2 \left( \frac{\partial^2 \varphi}{\partial x^2} + \frac{\partial^2 \varphi}{\partial y^2} \right)
\end{equation*}
Setzt man dies in die Gleichung \eqref{neuronal:generelle_feldgleichung} ein, entspricht sie der Wellengleichung in zwei Dimensionen.

Ziel ist es, die Lösung $\varphi(x, t)$ mit einem neuronalen Netzwerk $\hat{\varphi}(x, t; \vartheta)$ zu approximieren.
Das Netzwerk verfügt über einen Vektor \( \vartheta \in \mathbb{R}^n \) von \emph{trainierbaren Parametern}.
Diese Parameter sollen so gewählt werden, dass das neuronale Netzwerk $\hat{\varphi}(x, t; \vartheta)$ die gesuchte Funktion $\varphi(x, t)$ möglichst genau approximiert.

\subsection{Aufbau neuronaler Netzwerke}\label{neuronal:subsection:struktur_nn}
In diesem Abschnitt wird erläutert, was neuronale Netzwerke sind und wie sie aufgebaut sind.
Grundsätzlich bestehen neuronale Netzwerke aus der Verkettung mehrerer Teilfunktionen:

\begin{equation}
    \hat{\varphi}(x, t; \vartheta) = f_j \circ \ldots \circ f_i \ldots \circ f_1(x, t).
    \label{neuronal:nn_ausformuliert}
\end{equation}

Jede Teilfunktion \( f_i \) setzt sich aus einer affinen Transformation und einer anschliessenden nicht-linearen Aktivierungsfunktion \( g_i \) zusammen:

\begin{align*}
    f_i\colon \mathbb{R}^q & \longrightarrow \mathbb{R}^p \\
    v & \longmapsto g_i(A_i v + b_i)
\end{align*}

Hierbei ist \( v \in \mathbb{R}^q \), \( A_i \in \mathbb{R}^{p \times q} \) und \( b_i \in \mathbb{R}^p \). Die Elemente aller Matrizen \( A_i \) und Vektoren \( b_i \) bilden den Vektor \( \vartheta \), der die \emph{trainierbaren Parameter} des Netzwerks enthält.
Die Aktivierungsfunktion \( g_i \) wird elementweise auf das Ergebnis der affinen Transformation angewendet.
Die Wahl der Aktivierungsfunktion hängt stark von der zu approximierenden Funktion ab und kann beispielsweise der hyperbolische Tangens sein.

Die Definitions- und Wertebereiche der Teilfunktionen \( f_i \) sind flexibel wählbar, jedoch muss der Wertebereich einer jeden Teilfunktion \( f_i \) mit dem Definitionsbereich der nachfolgenden Teilfunktion \( f_{i+1} \) übereinstimmen.
Die Anzahl der Teilfunktionen ist nicht strikt vorgegeben, jedoch müssen der Definitionsbereich der ersten Teilfunktion \( f_1 \) und der Wertebereich der letzten Teilfunktion \( f_k \) festgelegt sein. 
Für das Netzwerk, das die Lösung der Feldgleichung approximiert, müssen diese Bereiche \( \mathbb{R}^2 \) bzw. \( \mathbb{R} \) sein.

Allgemein gilt, dass die Komplexität des zu approximierenden Problems die Grösse des neuronalen Netzwerks bestimmt: Je komplexer die Funktion, desto grösser muss das Netzwerk sein.

Im Abschnitt \ref{neuronal:section:rechenbeispiel} werden konkrete Definitionen für neuronale Netzwerke zur Lösung der Wellengleichung und der Burgers-Gleichung beschrieben.
Der Source-Code dieser Netzwerke ist im GitHub-Repository des Seminars verfügbar \cite{neuronal:github_source_code}.

Hier ein Beispiel für die Implementierung eines neuronalen Netzwerks mit zwei Teilfunktionen mit der Python-Bibliothek PyTorch:

\begin{lstlisting}
# Definition des Netzwerks
t1 = nn.Linear(2, 10)  # Affine Transformation mit Input: R^2, Output: R^10
t2 = nn.Linear(10, 1)
activation = nn.Tanh()

# Auswerten an einem gegebenen Input x
temp = activation(t1(x))
out = activation(t2(temp))
\end{lstlisting}

\subsection{Formulierung als Optimierungsproblem}\label{neuronal:subsection:optimierungsproblem}
In diesem Abschnitt wird die Wahl der \emph{trainierbaren Parameter} $\vartheta$ des neuronalen Netzwerks behandelt.
Die Auswahl von $\vartheta$ stellt im Wesentlichen ein Minimierungsproblem dar.
Die grundlegende Idee besteht darin, eine Funktion \( L(\vartheta) \) zu definieren, die den Approximationsfehler des Netzwerks quantifiziert.
Anschliessend wird diese Funktion minimiert, um die optimalen Parameter $\vartheta$ zu finden, die eine bestmögliche Approximation ermöglichen.

Um \( L(\vartheta) \) zu konstruieren, werden die Feldgleichung und die Anfangs- und Randbedingungen zunächst umgeformt.
Alle Terme werden auf eine Seite gebracht und anschliessend quadriert, um positive Fehlerwerte zu erhalten.
Für die Feldgleichung ergibt sich:
\begin{equation}
    \left(\mathcal{D}(\varphi(x, t))\right)^2 = 0 \qquad x \in \Omega, \quad t \in [0,T].
    \label{neuronal:feldgleichung_umformuliert}
\end{equation}
Analog werden die Anfangs- und Randbedingungen umgeformt:
\begin{equation}
    \begin{aligned}
        \left(f(x) - \varphi(x, t = 0)\right)^2 = 0 \qquad x \in \Omega\\
        \left(g(x) - \partial_t \varphi(x, t = 0)\right)^2 = 0 \qquad x \in \Omega
    \end{aligned}
    \label{neuronal:anfangsbedingung_umformuliert}
\end{equation}
und
\begin{equation}
    \begin{aligned}
        \left(\varphi(x, t)\right)^2 = 0 \qquad x \in \partial \Omega, \quad t \in [0,T].
    \end{aligned}
    \label{neuronal:randbedingung_umformuliert}
\end{equation}
Dann wird das neuronale Netzwerk $\hat{\varphi}$ anstelle von $\varphi$ eingesetzt:
\begin{equation}
    \left(\mathcal{D}(\hat{\varphi}(x, t; \vartheta))\right)^2 \qquad x \in \Omega, \quad t \in [0,T]
    \label{neuronal:feldgleichung_umformuliert_netz}
\end{equation}
\begin{equation}
    \begin{aligned}
        \left(f(x) - \hat{\varphi}(x, t = 0; \vartheta)\right)^2 \qquad x \in \Omega\\
        \left(g(x) - \partial_t \hat{\varphi}(x, t = 0; \vartheta)\right)^2 \qquad x \in \Omega
    \end{aligned}
    \label{neuronal:anfangsbedingung_umformuliert_netz}
\end{equation}
\begin{equation}
    \begin{aligned}
        \left(\hat{\varphi}(x, t; \vartheta)\right)^2 \qquad x \in \partial \Omega, \quad t \in [0,T].
    \end{aligned}
    \label{neuronal:randbedingung_umformuliert_netz}
\end{equation}
Ziel ist es, $\vartheta$ so zu wählen, dass alle diese Terme möglichst nahe bei 0 liegen.
Anders ausgedrückt, soll $\vartheta$ so gewählt werden, dass die Fehlerterme minimiert werden.

Es ist wichtig zu beachten, dass die Fehlerterme für alle $x$ und $t$ in den jeweiligen Bereichen minimiert werden müssen.
Bevor $L(\vartheta)$ definiert werden kann, müssen daher $x$ und $t$ diskretisiert werden.

\subsection{Diskretisierung}\label{neuronal:subsection:diskretierung}
Für die Diskretisierung werden drei Datensätze benötigt:
\begin{equation}
    \begin{aligned}
        F &= \{\, (x, t) \,|\, x \in \Omega \setminus \partial \Omega\,, t \in (0,T] \,\}\\
        A &= \{\, (x, t) \,|\, x \in \Omega \setminus \partial \Omega\,, t = 0 \,\}\\
        B &= \{\, (x, t) \,|\, x \in \partial \Omega\,, t \in [0, T] \,\}.
    \end{aligned}
\end{equation}
Jeder Datensatz besteht aus $k$ Punkten in den jeweiligen Bereichen.
Für diese Punkte gelten:
\begin{itemize}
    \item Die Feldgleichung für die Punkte in $F$
    \item Die Anfangsbedingungen für die Punkte in $A$
    \item Die Randbedingungen für die Punkte in $B$
\end{itemize}
Die Fehlerterme werden über die zugehörigen Datensätze summiert und gemittelt:
\begin{equation}
    \frac{1}{k} \sum_{F}^{} \left(\mathcal{D}(\hat{\varphi}(x_i, t_i; \vartheta))\right)^2
    \label{neuronal:feldgleichung_umformuliert_netz_disk}
\end{equation}
\begin{equation}
    \begin{aligned}
        \frac{1}{k} \sum_{A}^{} \left(f(x_i) - \hat{\varphi}(x_i, t_i = 0; \vartheta)\right)^2\\
        \frac{1}{k} \sum_{A}^{} \left(g(x_i) - \partial_t \hat{\varphi}(x_i, t_i = 0; \vartheta)\right)^2
    \end{aligned}
    \label{neuronal:anfangsbedingung_umformuliert_netz_disk}
\end{equation}
\begin{equation}
    \begin{aligned}
        \frac{1}{k} \sum_{B}^{} \left(\hat{\varphi}(x_i, t_i; \vartheta)\right)^2 &.
    \end{aligned}
    \label{neuronal:randbedingung_umformuliert_netz_disk}
\end{equation}
Diese Terme hängen nur noch von $\vartheta$ ab und sollen nach wie vor möglichst nahe bei 0 liegen.
Wie im vorherigen Abschnitt beschrieben, wird eine Funktion $L(\vartheta)$ definiert, die den Approximationsfehler misst.
Durch Addition der linken Seiten der obigen Terme kann \( L \) wie folgt definiert werden:
\begin{equation}
    \begin{aligned}
        L(\vartheta) =\quad &\frac{1}{k} \sum_{F}^{} \left(\mathcal{D}(\hat{\varphi}(x_i, t_i; \vartheta))\right)^2\\
        + &\frac{1}{k} \sum_{A}^{} \left(\left(f(x_i) - \hat{\varphi}(x_i, t_i = 0; \vartheta)\right)^2
        + \left(g(x_i) - \partial_t \hat{\varphi}(x_i, t_i = 0; \vartheta)\right)^2\right)\\
        + &\frac{1}{k} \sum_{B}^{} \left(\hat{\varphi}(x_i, t_i; \vartheta)\right)^2
    \end{aligned}
    \label{neuronal:optimierung}
\end{equation}
Für jede der drei Summen in \( L \) gilt:
\begin{itemize}
    \item Je genaür die Approximation des Netzwerks, desto näher bei 0
    \item Ist die Approximation perfekt (also \( \hat{\varphi} = \varphi \)) ist die Summe gleich 0
\end{itemize}
Dies bedeutet, je näher \( L \) bei 0 ist, desto besser ist die Approximation des Netzwerks.
$L$ ist daher tatsächlich ein Mass für den Approximationsfehler des Netzwerks.
Genaür gesagt, ist $L$ der mittlere Fehler über alle Datenpunkte der Diskretisierung.

Die Wahl der Parameter des neuronalen Netzwerks ist nun ein Minimierungsproblem:
\begin{aufgabe}
    Minimiere $L(\vartheta)$, wobei das $\vartheta$ am Minimum für die Approximation geeignet ist.
\end{aufgabe}

\subsection{Lösen des Minimierungsproblems}\label{neuronal:subsection:lösen_optimierungsproblem}
\( L \) lässt sich aus zwei Gründen nicht analytisch minimieren:
\begin{enumerate}
    \item \( L \) hängt von \( \vartheta \in \mathbb{R}^n \) ab. 
    Es müssten also alle \( n \) partiellen Ableitungen berechnet und nullgesetzt werden. 
    Da \( n \) eine sehr grosse Zahl ist, lässt sich das resultierende Gleichungssystem kaum lösen.
    \item Zudem würde das Lösen dieses Gleichungssystems voraussetzen, dass man die Feldgleichung löst, da diese in $L$ vorkommt.
\end{enumerate}
Das bedeutet, dass stattdessen ein numerischer Algorithmus verwendet werden muss.

\begin{aufgabe}
    Algorithmus (Gradientenabstieg)
    \begin{enumerate}
        \item Initialisiere \( \vartheta_1 \) mit Anfangswerten.
        \item \textbf{Schleife} von \( i = 1 \) bis \( i = m - 1 \):
        \begin{itemize}
            \item Berechne neü Parameterwerte: \( \vartheta_{i+1} = \vartheta_i - \varepsilon \nabla_\vartheta L\left(\vartheta_i\right) \). (Erklärung unten)
        \end{itemize}
        \item Gebe die Parameter \( \vartheta_m \) zurück.
    \end{enumerate}
    \label{neuronal:gradient_descent}
\end{aufgabe}

Die Anzahl der Schleifendurchläufe \( m \), also das Abbruchkriterium des Algorithmus, ist nicht streng festgelegt.
In dieser Arbeit wird in jedem Durchlauf des Algorithmus der aktuelle Wert \( L(\vartheta_i) \) berechnet.
Der Algorithmus wird beendet, sobald sich der Wert von \( L \) über mehrere Iterationen nur noch minimal ändert.
Abbildung~\ref{fig:gradientenabstieg_beispiel} veranschaulicht ein exemplarisches Beispiel eines Gradientenabstiegs.
Der Startpunkt wurde willkürlich im grünen Punkt gewählt.
Der rote Punkt markiert das lokale Minimum, während die schwarz gestrichelte Kurve den Verlauf des Gradientenabstiegs darstellt.
Gemäß dem oben beschriebenen Algorithmus~\ref{neuronal:gradient_descent} wird der Fehler in Richtung dieses lokalen Minimums optimiert.

Nach Abschluss dieses Algorithmus ist das neuronale Netzwerk mit den Parametern \( \vartheta_m \) vollständig trainiert.

\begin{figure}[H]
    \centering
    \hspace*{-0.1\textwidth}
    \includegraphics[width=0.9\textwidth]{papers/neuronal/images/gd_close_to_minima_long_distances_with_line.png}
    \caption{Beispiel eines Gradientenabstiegs zu einem lokalen Minimum}
    \label{fig:gradientenabstieg_beispiel}
\end{figure}


\subsubsection{Optimierungsverfahren und seine Grenzen}\label{neuronal:subsubsection:optimierungsverfahren_grenzen}

Der Algorithmus passt die Parameter des neuronalen Netzwerks schrittweise an, um die Verlustfunktion \( L(\vartheta) \) zu minimieren. Die Schrittweite wird durch den Parameter \( \varepsilon \) gesteuert, um ein Überspringen des Minimums zu vermeiden.

Die Hauptgrenzen des Verfahrens sind:
\begin{itemize}
    \item \textbf{Lokale Minima:} Der Algorithmus kann in einem lokalen Minimum stecken bleiben, insbesondere bei Funktionen mit vielen lokalen Minima.
    \item \textbf{Sattelpunkte und Maxima:} Der Algorithmus kann auf Sattelpunkten oder Maxima landen, wo der Gradient null ist und keine weitere Bewegung möglich ist.
    \item \textbf{Approximationsfehler:} Der gefundene Punkt muss einen akzeptablen Approximationsfehler aufweisen. Ein lokales Minimum mit geringem Fehler ist oft ausreichend.
\end{itemize}

Um diese Einschränkungen zu überwinden, können folgende Strategien angewendet werden:
\begin{itemize}
    \item \textbf{Dynamische Anpassung der Lernrate:} Eine Anpassung von \( \varepsilon \) kann helfen, lokale Minima zu vermeiden.
    \item \textbf{Fortgeschrittene Optimierungsalgorithmen:} Methoden wie Momentum oder Adam können die Konvergenz verbessern und das Risiko, in lokalen Minima stecken zu bleiben, verringern.
\end{itemize}

% \textbf{Als abschliessende Notiz:} Im Schritt 2 des Algorithmus werden die Parameterwerte neu berechnet.
% Durch die verwendete Formel wird erreicht, dass \( L(\vartheta_{i+1}) \leq L(\vartheta_i) \) ist, das heisst, der Fehler des Netzwerks nimmt mit jedem Schritt ab.
% Dies ist das Optimierungsverfahren \emph{Gradientenabstieg}.
%
% Das funktioniert, da der Gradient von \( L \) ausgewertet an \( \vartheta_i \) ein Vektor ist, der in die Richtung des stärksten Anstiegs auf \( L \), von \(\vartheta_i \) aus, weist.
% Durch das Minus in der Formel geht man in die entgegengesetzte Richtung, wo es auf \( L \) abwärts verläuft. 
% Mit \( \varepsilon \) wird die ``Schrittgrösse'' gesteuert, um zu verhindern, dass man über ein Minimum auf \( L \) ``springt''.
%
% Dieser Algorithmus birgt ein inhärentes Risiko.
% Es gibt keine Garantie dafür, dass das globale Minimum der Funktion \( L \) gefunden wird.
% Da der Algorithmus in jedem Schritt eine Abwärtsbewegung auf der Funktion \( L \) vollzieht, besteht die Möglichkeit, dass lediglich ein lokales Minimum erreicht wird.
% Befindet sich der Algorithmus in unmittelbarer Nähe eines lokalen Minimums, kann er dieses nicht mehr verlassen, da ein Anstieg erforderlich wäre, um sich von dort zu entfernen.
% Wenn die Funktion \( L \) zahlreiche lokale Minima aufweist, ist es sogar sehr wahrscheinlich, dass der Algorithmus eines davon findet.
% Dies muss jedoch nicht unbedingt als problematisch angesehen werden.
% Solange der Approximationsfehler des Netzwerks an dem gefundenen lokalen Minimum sehr nahe an 0 ist, spielt es keine Rolle, dass nicht das globale Minimum erreicht wurde. 
% Der Fehler muss sich lediglich in einem akzeptablen Bereich befinden.
%
% Eine weitere Gefahr besteht darin, dass der Gradient an allen Arten von Extrempunkten, nicht nur an Minima, den Wert 0 annimmt.
% Wenn der Algorithmus sich exakt auf einem Extrempunkt befindet, kann er sich von dort nicht mehr fortbewegen.
% Allerdings ist es äusserst unwahrscheinlich, dass dieser Fall eintritt, da der Algorithmus sich exakt auf dem Extrempunkt befinden müsste.
% Ist dies nicht der Fall und der Algorithmus befindet sich lediglich in der Nähe eines Extrempunkts, stellt dies kein Problem dar.
% Denn dort ist der Gradient bereits nicht mehr 0, und da es bei allen Extrempunkten -- mit Ausnahme der Minima -- in mindestens eine Richtung abwärts geht, wird der Algorithmus sich von dort wegbewegen.

\subsection{Qualitätsbewertung}\label{neuronal:subsection:qualitätsbewertung}
Für die Beurteilung der Qualität der Approximation bietet sich zunächst der Wert von \( L(\vartheta) \) nach Abschluss des Optimierungsalgorithmus an.
Dieser Wert gewährt Einblick in den mittleren Approximationsfehler, der bei den Datenpunkten aus der Diskretisierung auftritt.

Eine weitere Methode zur Bewertung besteht darin, einen Teil der drei Datensätze aus \ref{neuronal:subsection:diskretierung} nicht im Optimierungsalgorithmus zu verwenden, sondern vorher abzutrennen.
Anschliessend wird eine neue Funktion \( L^1(\vartheta) \) definiert, die analog zu \eqref{neuronal:optimierung} aufgebaut ist, mit dem Unterschied, dass nun über die abgetrennten (Teil-)Datensätze summiert wird.
Da diese Funktion nie explizit durch den Optimierungsalgorithmus minimiert wurde, dient sie als Mass für den mittleren Approximationsfehler bei Datenpunkten, die nicht in der Diskretisierung enthalten waren.

Eine letzte Möglichkeit zur Qualitätsbewertung bietet der direkte Vergleich mit Lösungen, die durch alternative Verfahren ermittelt wurden.
Existiert beispielsweise eine analytische Lösung der Feldgleichung oder wurde eine Lösung durch die Finite-Elemente-Methode erstellt, kann ein Vergleich mit diesen herangezogen werden.
