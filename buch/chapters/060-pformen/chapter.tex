%
% chapter.tex
%
% (c) 2025 Prof Dr Andreas Müller
%
\chapter{$p$-Formen und das Poincaré-Lemma
\label{chapter:pformen}}
\kopflinks{$p$-Formen und das Poincaré-Lemma}
In Abschnitt~\ref{buch:green:section:geschlossen} wurde gezeigt, dass eine
1-Form $\alpha$ mit $d\alpha=1$ in einem einfach zusammenhängenden Gebiet
mit Hilfe des Kurvenintegrals als Differential $df=\alpha$ einer Funktion
$f$ schreiben lässt.
In Kapitel~\ref{chapter:gauss} wurde angedeutet, dass etwas Ähnliches auch
für eine 2-Form auf $\mathbb{R}^3$ gilt.
In der Vektorsprache lässt sich ein Vektorfeld, welches verschwindende
Divergenz hat, als Rotation eines Vektorfeldes schreiben.
In diesem Kapitel soll gezeigt werden, dass beides nur Spezialfälle sind.
Dazu wird die allgemeine Theorie der $p$-Formen und der äusseren Ableitung
auf einer Mannigfaltigkeit entwickelt und gezeigt, 

%
% p-Formen
%
\section{$p$-Formen
\label{buch:pformen:section:pformen}}
\kopfrechts{$p$-Formen}


%
% Antisymmetrische Multilinearformen
%
\subsection{Antisymmetrische Multilinearformen auf $TM$}

\begin{definition}
Die Menge der $p$-Formen auf einer Mannigfaltigkeit wird mit $\Omega^p(M)$
geschrieben.
\end{definition}

\begin{satz}
Die $p$-Formen auf einer Mannigfaltigkeit bilden einen $\mathscr{E}(M)$-Modul.
In einer Karte kann eine $p$-Form $\omega\in \Omega^p(M)$ als
\begin{align*}
\omega
&=
\sum_{i_1<i_2<\dots< i_p}
f_{i_1 i_2\dots i_p}(x)
\, dx^{i_1}\wedge dx^{i_2}\wedge\dots\wedge dx^{i_p}
\\
&=
\frac{1}{p!}
\sum_{i_1,i_2,\dots,i_p}
f_{i_1 2_2\dots i_p}(x)
\, dx^{i_1}\wedge dx^{i_2}\wedge\dots\wedge dx^{i_p}
\end{align*}
geschrieben werden, wobei $f_{i_1 i_2\dots i_p}$  antisymmetrisch ist in jedem
Indexpaar.
\end{satz}

%
% Das \wedge-Produkt von $p$-Formen
%
\subsection{Das $\wedge$-Produkt}
Das Wedge-Produkt von Differentialformen ist eine bilineare Abbildung
\[
\Omega^p(M)\times \Omega^q(M) \to \Omega^{p+q}(M)
:
(\alpha,\beta) \mapsto \alpha\wedge\beta.
\]
Dies bedeutet, dass es ausreicht, das Wedge-Produkt auf einer Basis
zu definieren.

Seien jetzt also
\begin{align*}
\alpha &= dx^{i_1}\wedge\dots\wedge dx^{i_p} \\
\beta  &= dx^{j_{p+1}}\wedge\dots\wedge dx^{j_{p+q}}
\end{align*}
zwei Basis-$p$- bzw.~-$q$-Formen.
Es muss das Produkt
\begin{equation}
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\wedge
dx^{i_{p+1}}\wedge\dots\wedge dx^{i_{p+q}}
\label{buch:pformen:pformen:eqn:basisprodukt}
\end{equation}
durch Basis-$p+q$-Formen ausgedrückt werden.
Falls $(i_1,\dots,i_p)$ und $(i_{p+1},\dots,i_{p+q})$ einen Index gemeinsam
haben, dann verschwindet das Produkt.
Das Wedge-Produkt~\eqref{buch:pformen:pformen:eqn:basisprodukt}
ist also nur dann von $0$ verschieben, wenn alle Indizes in
$(i_1,\dots,i_p,i_{p+1},\dots,i_{p+q})$ verschieden sind.
Das Produkt~\eqref{buch:pformen:pformen:eqn:basisprodukt} ist aber
normalerweise keine Basis-$p+q$-Form, da in den Basisformen die
Indizes aufsteigend sind.
Die 1-Formen in \eqref{buch:pformen:pformen:eqn:basisprodukt} müssen
also so vertauscht werden, dass sich eine aufsteigende Reihenfolge
$(k_1,\dots,k_{p+q})$
der Indizes ergibt.
Bei jeder Vertauschung ändert das Vorzeichen.
Das Produkt \eqref{buch:pformen:pformen:eqn:basisprodukt} unterscheidet
sich also nur durch das Vorzeichen von 
\(
dx^{k_1}\wedge\dots\wedge dx^{k_{p+q}}
\).

Zur Bestimmung des Vorzeichens des Produktes $\alpha\wedge\beta$ 
sei $\sigma\in S_{p+q}$ die Permutation\footnote{Die Theorie der
Permutationen, der Gruppen $S_n$ und des Vorzeichens einer Permutation
wird ausführlich erklärt in \cite[Abschnitt~4.3.4]{buch:linalg}.}
der Zahlen $1,\dots,p+q$,
die $(i_1,\dots,i_p,i_{p+1},\dots,i_{p+q})$ in die geordnete
Reihenfolge
\[
(i_{\sigma(1)},\dots,i_{\sigma(p)},i_{\sigma(p+1)},\dots,i_{\sigma(p+q)})
=
(k_1,\dots,k_{p+q})
\]
überführt.
Die Anzahl $t(\sigma)$ der Vertauschungen, mit denen sich die
Permutation $\sigma$ schreiben lässt, ist nicht eindeutig bestimmt,
aber sie ist entweder gerade oder ungerade.
Das gesuchte Vorzeichen ist daher das sogenannte Signum
\[
\operatorname{sgn}(\sigma) = (-1)^{t(\sigma)}
\]
oder Vorzeichen der Permutation.

%
% Die Summenformel
%
\subsubsection{Die Summenformel}
Bei der konkreten Berechnung eines Wedge-Produktes ist es jeweils
einfach, die nötigen Vertauschungen vorzunehmen und damit das
richtige Vorzeichen zu finden.
Für die algebraische Rechnung ist dies jedoch etwas komplizierter,
da die Algebra keine gute Notation für die richtige Reihenfolge der
Indizes zu finden.

Um eine einfachere Formel zu finden, schreiben wir erst die Basis
auf eine neue Art.
Statt als Basisvektoren die Produkte von 1-Formen in einer vorgegebenen
Reihenfolge zu nehmen, lassen wir alle Reihenfolgen der Indizes zu.
Die so entstehenden Produkte unterscheiden sich nur durch ein
Vorzeichen.
Jedes der Produkte
\[
dx^{i_1}\wedge\dots\wedge dx^{i_p}
=
\operatorname{sgn}(\sigma)
\,
dx^{i_{\sigma(1)}} \wedge\dots\wedge dx^{i_{\sigma(p)}}
\]
für eine Permutation $\sigma\in S_p$ ist also gleichermassen geeignet
als Basisvektor.
Es gibt $p!$ solche Permutationen.
Damit wir die verschiedenen Basisvektoren gleichberechtigt verwenden
können, nehmen wir deren Mittelwert
\[
dx^{i_1}\wedge\dots\wedge dx^{i_p}
=
\frac{1}{p!}
\sum_{\sigma\in S_p} dx^{i_{\sigma(1)}} \wedge\dots\wedge dx^{i_{\sigma(p)}}
\]
Diese Summe ändert nicht, wenn die Indizes $i_1,\dots,i_p$ mit einer
geraden Permutation permutiert werden.

Eine beliebige $p$-Form ist in der Basis der
$dx^{i_1}\wedge\dots\wedge dx^{i_p}$  mit $i_1<\dots<i_p$
durch die Koeffizienten $f_{i_1\dots i_p}$ gegeben.
Die Forderung der aufsteigend sortierten Indizes in
\[
\omega
=
\sum_{i_1<\dots<i_p}
f_{i_1\dots i_p}\,
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\]
ist etwas schwerfällig.
Die Beschreibung wird einfacher, wenn man verlangt, dass die
Koeffizienten vollständig antisymmetrisch sind, also
\[
f_{i_1\dots i_p}
=
\operatorname{sgn}\,
f_{i_{\sigma(1)}\dots i_{\sigma(p)}}
\]
für jede Permutation $\sigma\in S_p$.
Damit fällt jetzt die Foderung nach aufsteigenden Indizes weg und man
kann
\begin{equation}
\omega
=
\frac{1}{p!}
\sum_{i_1,\dots,i_p=1}^n
f_{i_1\dots i_p}
\,
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\label{buch:pformen:pformen:eqn:summenformel}
\end{equation}
schreiben.

%
% Kommutativität
%
\subsubsection{Kommutativität}
Das Wedge-Produkt ist nicht kommutativ.
Für 1-Formen gilt $dx^i\wedge dx^k=-dx^k\wedge dx^i$.
Es ist aber auch nicht antikommutativ, denn 
\[
(dx^2\wedge dx^3)\wedge dx^1
=
-dx^2\wedge dx^1\wedge dx^3
=
dx^1\wedge dx^2\wedge dx^3,
\]
in diesem Fall ändert das Vorzeichen bei der Vertauschung der
Faktoren $dx^1$ und $dx^2\wedge dx^3$ nicht.
Der Grund ist, dass {\em zwei} Vertauschungen nötig sind, um
die Faktoren in die Standardreihenfolge zu bringen.
Wir beweisen die folgende Kommutationsformel.

\begin{satz}
Für eine $p$-Form $\alpha\in\Omega^p(M)$ und eine $q$-Form
$\beta\in\Omega^q(M)$ gilt
\begin{equation}
\alpha\wedge\beta
=
(-1)^{pq}\,\beta\wedge\alpha.
\label{buch:pformen:pformen:eqn:kommutativ}
\end{equation}
\end{satz}

\begin{proof}
Wir müssen zeigen, dass die
Formel~\eqref{buch:pformen:pformen:eqn:kommutativ}
Für die Basisdifferentialformen gilt.
Wir verwenden die Farben {\color{darkred}rot} und {\color{blue}blau},
um die Vertauschungen der 1-Form-Faktoren duetlich zu machen.
Wir schreiben also
\begin{align*}
{\color{darkred}\alpha}
&=
{\color{darkred}dx^{i_1}}
\wedge \dots \wedge
{\color{darkred}dx^{i_p}}
\\
\text{und}\qquad
{\color{blue}\beta}
&=
{\color{blue}dx^{k_1}}
\wedge \dots \wedge
{\color{blue}dx^{k_p}}
\end{align*}
und berechnen die Produkte $\alpha\wedge\beta$ und $\beta\wedge\alpha$.
Um das Produkt $\beta\wedge\alpha$ in die Reihenfolge der 1-Form-Faktoren
von $\alpha\wedge\beta$ zu bringen, sind jeweils Vertauschungen mit
Nachbarfaktoren notwendig:
\begin{align*}
{\color{darkred}\alpha}\wedge{\color{blue}\beta}
&=
{\color{darkred}dx^{i_1}}
\wedge\dots\wedge
{\color{darkred}dx^{i_p}}
\wedge
{\color{blue}dx^{k_1}}
\wedge\dots\wedge
{\color{blue}dx^{k_q}}
\\
&=
{\color{darkred}dx^{i_1}}
\wedge\dots\wedge
{\color{blue}dx^{k_1}}
\wedge
{\color{darkred}dx^{i_p}}
\wedge
{\color{blue}dx^{k_2}}
\wedge\dots\wedge
{\color{blue}dx^{k_q}}
\\
&=
(-1)^p
\,
{\color{blue}dx^{k_1}}
\wedge
{\color{darkred}dx^{i_1}}
\wedge\dots\wedge
{\color{darkred}dx^{i_p}}
\wedge
{\color{blue}dx^{k_2}}
\wedge\dots\wedge
{\color{blue} dx^{k_q}}
\\
&=
(-1)^2q
\,
{\color{blue}dx^{k_1}}
\wedge
{\color{blue}dx^{k_2}}
\wedge
{\color{darkred}dx^{i_1}}
\wedge\dots\wedge
{\color{darkred}dx^{i_p}}
\wedge
{\color{blue}dx^{k_3}}
\wedge\dots\wedge
{\color{blue} dx^{k_q}}
\\
&=
(-1)^{pq}
\,
{\color{blue}dx^{k_1}}
\wedge\dots\wedge
{\color{blue}dx^{k_q}}
\wedge
{\color{darkred}dx^{i_1}}
\wedge\dots\wedge
{\color{darkred}dx^{i_p}}
\\
&=
(-1)^{pq}
\,
{\color{blue}\beta}\wedge{\color{darkred}\alpha}.
\end{align*}
Damit ist die Formel bewiesen.
\end{proof}

%
% Die graduierte Algebra der p-Formen
%
\subsection{Die graduierte Algebra der $p$-Formen}
Die Räume $\Omega^p(M)$ haben für verschiedene $0$ keine gemeinsamen 
nichttrivialen Formen.
Die Nullform, die auf jedem beliebigen $p$-Vektor verschwindet, kann man
aber durchaus als ein gemeinsames Element betrachten.
Rein Formale kann man daher auch Linearkombinationen von $p$-Formen für
verschiedenes $p$ bilden.
So entsteht die Menge
\[
\Omega^*(M)
=
\bigoplus_{p=0}^n \Omega^p (M)
\]
der Differentialformen auf der Mannigfaltigkeit.
$\Omega^*(M)$ ist ein reeller Vektorraum: Differentialformen können mit
Zahlen multipliziert und addiert werden.

Die $0$-Formen sind die Funktionen und können mit glatten Funktionen in
$\Omega^0(M)=\mathscr{E}(M)$ multipliziert werden.
Die glatten Funktionen bilden keinen Körper, da man durch Funktionen mit
Nullstellen nicht dividieren kann.
Die glatten Funktionen bilden aber einen sogenannten Ring. 
\index{Ring}%
Es sind alle Rechenregeln definiert, die auch in einem Körper gelten,
ausser die Existenz eines multiplikativen Inversen.

Die Differentialformen können mit Funktionen in $\mathscr{E}(M)$
multipliziert werden.
Dadurch wird $\Omega^*(M)$ zu einem sogenannten {\em Modul} über
dem Ring $\mathscr{E}(M)$.
Wenn $f\in\mathscr{E}(M)$ eine glatte Funktion und $\omega\in\Omega^p(M)$
eine $p$-Form ist, dann ist $f\omega\in\Omega^p(M)$ ebenfalls eine
$p$-Form.
Die Multiplikation mit einer glatten Funktion ändert den Grad einer
$p$-Form nicht.
Jeder einzelne Summand $\Omega^p(M)\subset\Omega^*(M)$ ist also für
sich genommen ebenfalls ein $\mathscr{E}(M)$-Modul.
Man nennt $\Omega^*(M)$ daher einen {\em graduierten} $\mathscr{E}(M)$-Modul.
\index{graduiert}%
\index{Modul!graduiert}%

Das Wedge-Produkt der Differentialformen verknüpft eine $p$-Form
$\alpha\in\Omega^p(M)$ mit einer $q$-Form $\beta\in\Omega^q(M)$
zu einer $p+q$-Form $\alpha\wedge\beta\in\Omega^{p+q}(M)$.
Die Menge $\Omega^*(M)$ hat also nicht nur die Struktur eines
Moduls über dem Ring $\mathscr{E}(M)$ sondern auch die Struktur
einer Algebra über dem Ring $\mathscr{E}(M)$.
Das Produkt respektiert aber auch die Graduierung von $\Omega^*(M)$,
daher heisst $\Omega^*(M)$ auch eine graduierte $\mathscr{E}(M)$-Algebra.

%
% Die äussere Ableitung
%
\section{Die äussere Ableitung
\label{buch:pformen:section:aeussereableitung}}
\kopfrechts{Die äussere Ableitung}
Für 1-Formen, 2-Formen und $n-1$-Formen wurde die äussere
Ableitung bereits definiert.
Auf Basisdifferentialformen ist die äussere Ableitung
durch die ausreichend verschiedenen Formeln
\begin{align*}
d(
f\,dx^i
)
&=
\frac{\partial f}{\partial x^k}\, dx^k\wedge dx^i
\\
d(g\,dx^i\wedge dx^k)
&=
\sum_{l=1}^n
\frac{\partial g}{\partial x^l}\, dx^l\wedge dx^i\wedge dx^k
\\
d(h\,
dx^1\wedge\dots\wedge \widehat{dx^i}\wedge\dots\wedge dx^n
)
&=
\frac{\partial h}{\partial x^i}
\,
dx^i\wedge
(dx^1\wedge\dots\wedge \widehat{dx^i}\wedge\dots\wedge dx^n)
\\
&=
(-1)^{n-1}
\frac{\partial h}{\partial x^i}
\,
dx^1\wedge\dots\wedge dx^n.
\end{align*}
gegeben.
Für die weitere Entwicklung brauchen wir eine Definition, die in allen
Fällen anwendbar ist.

%
% Definition der äusseren Ableitung
%
\subsection{Definition der äusseren Ableitung}
Die äussere Ableitung ist linear, es reicht daher, sie auf
Basisdifferentialformen zu definieren.

\begin{definition}[Äussere Ableitung]
Die äussere Ableitung der Basis-$p$-Form 
$\alpha=f(x)\, dx^{i_1}\wedge\dots\wedge dx^{i_p}$
ist
\[
d\alpha
=
\sum_{k=1}^n
\frac{\partial f}{\partial x^k}
\,dx^k\wedge
dx^{i_1}\wedge\dots\wedge dx^{i_p}.
\]
\end{definition}

Für eine beliebige $p$-Form
\[
\omega
=
\sum_{i_1<\dots <i_p}
f_{i_1\dots i_p}\, dx^{i_1}\wedge\dots\wedge dx^{i_p}
\]
kann die äussere Ableitung daher als
\[
d\omega
=
\sum_{k=1}^n
\sum_{i_1<\dots <i_p}
\frac{\partial f_{i_1\dots i_p}}{\partial x^k}
\,dx^k
\wedge
dx^{i_1}
\wedge
\dots
\wedge
dx^{i_p}
\]
geschrieben werden.
Verwendet man vollständig antisymmetrische Koeffizienten wie in
\eqref{buch:pformen:pformen:eqn:summenformel}, bekommt die
äussere Ableitung die Form
\[
d\omega
=
\frac{1}{p!}
\sum_{i_1,\dots,i_p=1}^n
\frac{\partial f_{i_1\dots i_p}}{\partial x^k}
\,
dx^k\wedge dx^{i_1}\wedge\dots\wedge dx^{i_p}.
\]

%
% Äussere Ableitung und Wedge-Produkt
%
\subsection{Äussere Ableitung und Wedge-Produkt}
Wir berechnen die äussere Ableitung des Wedge-Produkts zweier
Differentialformen.
Seien also $\alpha\in\Omega^p(M)$ und $\beta\in\Omega^q(M)$
Differentialformen auf der Mannigfaltigkeit.
Um die äussere Ableitung des Produktes $\alpha\wedge\beta$ zu
berechnen, gehen wir von einfachen Monomen
\[
\alpha
=
f\,dx^{i_1}\wedge\dots\wedge dx^{i_p}
\qquad\text{und}\qquad
\beta
=
g\,dx^{i_{p+1}}\wedge\dots\wedge dx^{i_{p+q}}
\]
aus.
Das Produkt ist
\[
\alpha\wedge\beta
=
f(x)\,g(x)\,
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\wedge
dx^{i_{p+1}}\wedge\dots\wedge d^{i_{p+q}}.
\]
Die äussere Ableitung ist
\begin{align*}
d(\alpha\wedge\beta)
&=
\sum_{k=1}^n
\frac{\partial(f\cdot g)}{\partial x^k}
dx^k
\wedge
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\wedge
dx^{i_{p+1}}\wedge\dots\wedge d^{i_{p+q}}
\\
&=
\sum_{k=1}^n
\biggl(
\frac{\partial f}{\partial x^k}(x)
g(x)
+
f(x)
\frac{\partial g}{\partial x^k}(x)
\biggr)\,
dx^k
\wedge
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\wedge
dx^{i_{p+1}}\wedge\dots\wedge d^{i_{p+q}}
\\
&=
\sum_{k=1}^n
\frac{\partial f}{\partial x^k}(x)\,
dx^k
\wedge
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\wedge
g(x)\,
dx^{i_{p+1}}\wedge\dots\wedge d^{i_{p+q}}
\\
&\qquad +
\sum_{k=1}^n
f(x)\,
dx^k
\wedge
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\wedge
\frac{\partial g}{\partial x^k}(x)\,
dx^{i_{p+1}}\wedge\dots\wedge d^{i_{p+q}}.
\intertext{Um den Faktor $dx^k$ im zweiten Summanden neben
die partielle Ableitung von $g$ zu bringen, sind $p$ Vertauschungen
nötig, die Ableitung wird dann}
&=
\biggl(
\sum_{k=1}^n
\frac{\partial f}{\partial x^k}(x)\,
dx^k
\wedge
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\biggr)
\wedge
g(x)\,
dx^{i_{p+1}}\wedge\dots\wedge d^{i_{p+q}}
\\
&\qquad +
f(x)\,
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\wedge
(-1)^p
\sum_{k=1}^n
\frac{\partial g}{\partial x^k}(x)\,
dx^k
\wedge
dx^{i_{p+1}}\wedge\dots\wedge d^{i_{p+q}}
\\
&=
d\alpha \wedge \beta
+
(-1)^p
\alpha\wedge d\beta.
\end{align*}
Abgesehen vom zusätzlichen Vorzeichen im zweiten Term ist dies
die Produktregel.

\begin{definition}
Eine {\em Antiderivation} $d$ einer graduierten Algebra $A$ ist eine
\index{Antiderivation}%
lineare Abbildung mit
\begin{equation}
d(\alpha\cdot\beta)
=
(d\alpha)\cdot\beta
+
(-1)^p \alpha\cdot(d\beta)
\label{buch:pformen:pformen:eqn:antiderivation}
\end{equation}
für $\alpha\in A^p$ und $\beta\in A^q$.
\end{definition}

Die äussere Ableitung ist also eine Antiderivation in der graduierten
Algebra der Differentialformen auf einer Mannigfaltigkeit.
Für eine Funktion $f\in\Omega^0(M)$, $p=0$, und $\beta\in\Omega^q(M)$ 
wird aus
\eqref{buch:pformen:pformen:eqn:antiderivation}
die bekannte Produktregel
\[
d(f\beta)
=
(df)\wedge \beta
+
f\wedge d\beta.
\]

\subsection{Geschlossene und exakte Formen}
% Definitionen der Begriffe geschlossen und exakt

\begin{definition}
Eine $p$-Form $\omega$ heisst {\em geschlossen}, wenn $d\omega=0$ ist.
\index{geschlossene $p$-Form}%
Eine $p$-Form heisst {\em exakt}, wenn es eine $p-1$-Form $\alpha$ gibt,
sodass $\omega = d\alpha$.
\index{exakte $p$-Form}%
\end{definition}


%
% Abbildung von p-Formen
%
\section{Abbildung von $p$-Formen
\label{buch:pformen:section:abbildung}}
\kopfrechts{Abbildung von $p$-Formen}%

\subsection{Abbildung von Funktionen}
% 

\subsection{Abbildung von 1-Formen}

\subsection{$p$-Formen}

\subsection{Einbettung einer Untermannigfaltigkeit}

%
% Das Poincaré-Lemma
%
\section{Das Poincaré-Lemma
\label{buch:pformen:section:poincarelemma}}
Das Poincaré-Lemma besagt, dass auf einem zusammenziehbaren Gebiet jede
geschlossene $p$-Form exakt ist.
Falls $d\omega=0$ ist, muss es also eine $p-1$-Form $\alpha$ geben mit
$d\alpha=\omega$.
Für geschlossene 1-Formen wurde dies bereits mit Hilfe von Kurvenintegralen
gezeigt.
In diesem Abschnitt soll diese Aussage für beliebige $p$-Formen
nachgewiesen werden.
Zu jeder geschlossenen $p$-Form muss eine Form geringeren Grades gefunden
werden, es müssen also irgendwie einzelne Faktoren $dx^i$ in Funktionen
umgewandelt werden.
Die Faser-Integration, die in
Abschnitt~\ref{buch:pformen:poincare:subsection:faserintegration}
definiert wird, erreicht dies.
Der Fall der 1-Formen verwendete die Wegunabhängigkeit von Wegintegralen
oder die Deformation von Wegen für die Konstruktion der Funktion.
Diese Idee der Deformation wird
in Abschnitt~\ref{buch:pformen:poincare:subsection:homotopie}
mit der Homotopie-Abbildung verallgemeinert.

%
% Homotopie und Restriktion
%
\subsection{Homotopie und Restriktion}
\input{chapters/060-pformen/fig/fig-homotopie.tex}%
Ist die 1-Form $\alpha$ auf einem offenen Ball $U\subset \mathbb{R}^n$
geschlossen, dann kann man eine Funktion $f$ finden, deren Differential
$df=\alpha$ ist.
Die Funktion $f$ entsteht durch Wegintegration z.~B.~vom Nullpunkt zum
Punkt $x$
\[
\gamma_x
\colon [0,1] \to U
:
t\mapsto \gamma_x(t) = xt.
\]
Betrachtet man $\gamma_x(t)$ als eine Funktion von zwei Variablen
$x$ und $t$, dann kann man sie schreiben als
\[
H
\colon
U\times[0,1]
\to
U
:
(x,t) \mapsto tx.
\]
Für jeden Wert von $t$ ist die partielle Funktion
\[
h_t \colon U \to U : x \mapsto tx
\]
eine Selbstabbildung von $U$.
Für $t=0$ wird jeder Punkt auf $0$ abgebildet, die Abbildung $h_0$ ist
die konstante Abbildung auf den Nullpunkt von $U$.
Fpr $t=1$ ist $h_1(x)=x$, $h_1$ ist also die identische Abbildung 
Man nennt $H$ eine {\em Homotopie} zwischen der konstanten Abbildung
und der identischen Abbildung.

Das Definitionsgebiet der Homotopie ist das karteische Produkt
$U\times[0,1]$.
Für jeden Wert von $\tau\in[0,1]$ ist die Abbildung
\[
i_\tau
\colon U \to U\times[0,1]
:
x\mapsto (x,\tau)
\]
eine Einbettung der $n$-dimensionalen Untermannigfaltigkeit $U$ in
$U\times[0,1]$.
Eine $p+1$-Form $\omega$ auf $U\times[0,1]$ wird durch $i_\tau^*$ zu
einer $i_\tau^*(\omega)$, die auf
\begin{align*}
i_\tau^*\bigl(
f(x,t)
\,dx^{i_1}\wedge \dots \wedge dx^{i_p}\wedge dt
\bigr)
&=
0
\\
i_\tau^*\bigl(
g(x,t)
\,dx^{i_1}\wedge \dots \wedge dx^{i_p}\wedge dx^{i_{p+1}}
\bigr)
&=
g(x,\tau)
\,dx^{i_1}\wedge \dots \wedge dx^{i_p}\wedge dx^{i_{p+1}}.
\end{align*}
Die Variable $t$ wird als Konstante mit dem Wert $\tau$ betrachtet.

%
% Faserintegration
%
\subsection{Faserintegration
\label{buch:pformen:poincare:subsection:faserintegration}}
\input{chapters/060-pformen/fig/fig-faserintegration.tex}%
Zu jeder $p+1$-Form $\omega$ mit $d\omega=0$ muss eine $p$-Form gefunden
werden.
Dazu müssen einzelne Faktoren $dx^i$ in einem Produkt
$dx^{i_1}\wedge\dots\wedge dx^{i_{p+1}}$ zum Verschwinden gebracht
werden.
Die einzige Möglichkeit, dies zu tun, ist über einzelne Koordinaten zu
integrieren.
Dies ist das Prinzip der Faser-Integration, die im folgenden Satz
definiert wird.

Für den Rest dieses Abschnitts verwenden wir folgende Notation.
Da es nur um lokale Fragen geht, können wir uns auf einzelne
Kartengebiete beschränken.
Wir betrachten daher Differentialformen auf einem offenen Ball
$U\subset\mathbb{R}^n$, in dem wir die Koordinaten mit $x^1,\dots,x^n$
bezeichnen.
Die Projektion $\pi$ ist die Abbildung
\[
\pi
\colon U \times [0,1]\to U : (x,t) \mapsto x,
\]
sie ist in Abbildung~\ref{buch:pformen:poincarelemma:fig:faserintegration}
dargestellt.

Die Projektion $\pi$ ermöglicht, eine $p$-Form $\omega$ auf $U$ in eine
$p$-Form $\pi^*(\omega)$ auf $U\times [0,1]$ abzubilden.
Wir benötigen aber eine andere Art von Abbildung.
Aus einer $p+1$-Form auf $U\times[0,1]$ möchten wir eine $p$-Form auf
$U$ erzeugen.
Dazu integrieren wir über die $t$-Koordinate, wie in der folgenden
Definition.

\begin{definition}
Die Faserintegration ist die linear Abbildung
$\pi_*\colon \Omega^{p+1}(M)\to\Omega^p(M)$, die auf Basisformen durch
\begin{align*}
\alpha
&=
a_{i_1 \dots i_p}(x,t)
\,
dx^{i_1}\wedge\dots\wedge dx^{i_p}\wedge dt
&&\Rightarrow&
\pi_*\bigl(
\alpha
\bigr)
&=
\biggl(
\int_0^1 a_{i_1 \dots i_p}(x,t)\,dt
\biggr)
\,
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\\
\beta
&=
b_{i_1 \dots i_{p+1}}(x,t)
\,
dx^{i_1}\wedge \dots \wedge dx^{i_{p+1}}
&&\Rightarrow&
\pi_*\bigl(\beta)
\bigr)
&=
0
\end{align*}
definiert ist.
\end{definition}

Die Faserintegration wirkt also nur auf $p$-Formen, die den Faktor $dt$
enthält.
Solche Faktoren werden über die Variable $t$ integriert.

Die Faserintegration ist nicht aus einer Abbildung der unterliegenden
Mannigfaltigkeiten entstanden (das wäre die Abbildung $\pi^*$).
Daher muss im nächsten Schritt ermittelt werden, wie Faserintegration
sich mit der äusseren Ableitung von Formen verträgt.

\begin{satz}[Faserintegration]
Sei $\omega\in\Omega^{p+1}(U\times[0,1])$ eine $p+1$-Form auf $U\times[0,1]$.
Dann  ist
\begin{equation}
\pi_*d\omega - d\pi_*\omega 
=
(-1)^p(i_1^*\omega- i_0^*\omega)
\label{buch:pformen:poincarelemma:eqn:pid}
\end{equation}
für jede $p$-Form $\omega\in\Omega^p(U\times[0,1])$.
\end{satz}

\begin{proof}
Wir berechnen die Ableitungen und die Faserintegration der
Basis-$p+1$-Formen
\begin{align*}
\alpha
&=
a_{i_1 \dots i_p}(x,t)
\,
dx^{i_1}\wedge \dots \wedge dx^{i_p}\wedge dt
\\
\beta
&=
b_{i_1 \dots i_p i_{p+1}}(x,t)
\,
dx^{i_1}\wedge \dots \wedge dx^{i_p}\wedge dx^{i_{p+1}}
\end{align*}
auf $U\times[0,1]$.

Da $\alpha$ bereits $dt$ enthält, kommen in $d\alpha$ keine Ableitungen
von $a_{i_1\dots i_p}$ nach der Zeit vorkommen.
Die Ableitungen sind:
\begin{align*}
d\alpha
&=
\sum_{k=1}^n \frac{\partial a_{i_1\dots i_p}(x,t)}{\partial x^k}
\,dx^k\wedge dx^{i_1}\wedge \dots \wedge dx^{i_p}\wedge dt
\\
d\beta
&=
\sum_{k=1}^n \frac{\partial b_{i_1\dots i_{p+1}}(x,t)}{\partial x^k}
\,dx^k\wedge dx^{i_1}\wedge \dots \wedge dx^{i_{p+1}}
+
\frac{\partial b_{i_1\dots i_{p+1}}(x,t)}{\partial t}
\,dt\wedge dx^{i_1}\wedge \dots\wedge dx^{i_{p+1}}
\intertext{Die Faserintegration erhält nur die Terme mit $dt$ und 
ergibt}
\pi_*d\alpha
&=
\sum_{k=1}^n
\biggl(
\int_0^1 \frac{\partial a_{i_1\dots i_p}(x,t)}{\partial x^k}
\,dt
\biggr)
\,
dx^k
\wedge
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\\
\pi_*d\beta
&=
\biggl(
\int_0^1
\frac{\partial b_{i_1 \dots i_{p+1}}(x,t)}{\partial t}
\,dt
\biggr)
\,
(-1)^{p+1}
\,
dx^{i_1}\wedge\dots \wedge dx^{i_{p+1}}
\\
&=
\Bigl(
b_{i_1\dots i_{p+1}}(x,1)
-
b_{i_1\dots i_{p+1}}(x,0)
\Bigr)
\,
(-1)^{p+1}
\,
dx^{i_1}\wedge\dots\wedge dx^{i_p}\wedge dx^{i_{p+1}}
\intertext{Die beiden Summanden im letzten Ausdruck entstehen dadurch,
dass die Variable $t$ auf $0$ bzw.~$1$, das ist}
&=
(-1)^{p+1}
\bigl(
i_1^*\beta - i_0^*\beta
\bigr).
\end{align*}

Wir berechnen jetzt die Wirkung der Operatoren $\pi^*$ und $d$ in der
umgekehrten Reihenfolge.
Da $\pi^*\beta=0$ ist auch $d\pi^*\beta=0$.
Für $\alpha$ ist etwa mehr Arbeit notwendig.
\begin{align*}
d\pi_*\alpha
&=
\sum_{k=1}^n
\frac{\partial}{\partial x_k}
\biggl(
\int_0^1 a_{i_1\dots i_p}(x,t)\,dt
\biggr)
dx^k\wedge dx^{i_1}\wedge\dots\wedge dx^{i_p}
\intertext{Die Ableitung kann ins Integral genommen werden und ergibt}
&=
\sum_{k=1}^n
\biggl(
\int_0^1 \frac{\partial a_{i_1\dots i_p}(x,t)}{\partial x_i} \,dt
\biggl)
\,
dx^k
\wedge
dx^{i_1}\wedge\dots\wedge dx^{i_p}
\\
&=
\pi_*d\alpha.
\end{align*}

Die Rechnung in den vorangegangenen Absätzen zeigt also, dass
\begin{align}
\pi_*d\alpha - d\pi_*\alpha
&=
0,
\label{buch:pformen:poincarelemma:eqn:i*alpha}
\\
\pi_*d\beta - d\pi_*\beta
&=
(-1)^{p+1}
\bigl(
i_1^*\beta - i_0^*\beta
\bigr).
\notag
\end{align}
Da in den Termen der Form $\alpha$ immer der Faktor $dt$ vorkommt, 
der von $i_\tau^*$ auf $0$ abgebildet wird, gilt $i_t^*\alpha=0$
und man kann die Null auf der rechten Seite von 
\eqref{buch:pformen:poincarelemma:eqn:i*alpha}
ebenfalls als
\(
\pi_*d\alpha-d\pi*\alpha=(-1)^{p+1}\bigl(i_1^*\alpha-i_0^*\alpha\bigr)
\)
schreiben.
Damit ist die Formel
\eqref{buch:pformen:poincarelemma:eqn:pid}
bewiesen.
\end{proof}

%
% Homotopie-Abbildung
%
\subsection{Homotopie-Abbildung
\label{buch:pformen:poincare:subsection:homotopie}}
Die Homotopie $H\colon U\times[0,1]\to U$ ist eine differenzierbare
Abbildung.
Die induzierte Abbildung $H^*\colon\Omega^*(U)\to\Omega^*(U\times[0,1])$
vertauscht mit $d$.
Für eine $p$-Form $\omega$ auf $U$ ist $H^*\omega$ eine $p$-Form auf
$U\times[0,1]$.
Entsprechend ist $\pi_*H^*\omega$ ist eine $p-1$-Form auf $U$.
Wir definieren daher die Funktion $J=\pi_*H^*$ und berechnen das
Verhalten mit der äusseren Ableitung.

\begin{satz}
\label{buch:pformen:poincarelemma:satz:homotopie}
Für jede $p$-Form $\omega\in\Omega^p(U)$ gilt
\[
Jd\omega - dJ\omega
=
h_1^*\omega - h_0^*\omega
\]
\end{satz}

\begin{proof}
\begin{align*}
J d \omega - d J \omega
&=
\pi_* H^* d \omega
-
d \pi^* H^* \omega
\\
&=
\pi_* d H^* \omega
-
d \pi^* H^* \omega
\\
&=
d \pi_* H^* \omega
+
(-1)^p(i_1^* H^* \omega - i_0^* H^* \omega)
-
d \pi^* H^* \omega.
\intertext{Der erste und der letzte Term heben sich weg.
Im mittleren Term ist $H\circ i_\tau=h_\tau$ und daher
$i_\tau^* H^* = (H\circ i_\tau)^* = h_\tau^*$.
Somit folgt}
J d \omega - d J \omega
&=
(-1)^p(h_1^* \omega - h_0^* \omega).
\end{align*}
wie behauptet.
\end{proof}

%
% Geschlossene Formen sind exakt
%
\subsection{Geschlossene Formen sind exakt}
Mit der Faserintegration und der Homotopie-Abbildung wurde
in Abschnitt~\ref{buch:pformen:poincare:subsection:homotopie}
die Abbildung $J$ konstruiert, deren Eigenschaften im
Satz~\ref{buch:pformen:poincarelemma:satz:homotopie}
zusammengestellt wurden.
Damit ist es jetzt möglich, das Poincaré-Lemma zu beweisen.

\begin{satz}[Poincaré-Lemma]
Ist die $p$-Form $\omega\in\Omega^p(U)$ geschlossen, also $d\omega=0$,
dann gibt es eine $p-1$-Form $\alpha\in\Omega^{p-1}(U)$ mit
$d\alpha=\omega$.
\end{satz}

\begin{proof}
Nach Satz~\ref{buch:pformen:poincarelemma:satz:homotopie} folgt
wegen $d\omega=0$ sofort
\[
dJ\omega
=
h_1^*\omega - h_0^*\omega.
\]
Die Abbildung $h_0$ ist die konstante Abbildung $x\mapsto 0$, also ist ist
$h_0^*\omega=0$.
$h_1$ ist die identische Abbildung $x\mapsto x$, daher ist auch $h_1^*$
die identische Abbildung von $\Omega^*(U)$ und daher $h_1^*\omega=\omega$.
Damit filgt $dJ\omega=\omega$.
Somit ist $\alpha =J\omega$ die gesuchte $p-1$-Form.
\end{proof}

Wir prüfen nach, dass der ursprünglich für geschlossene 1-Formen
$\omega$ gegebene Beweis die gleiche Funktion
$f=J\omega\in\Omega^0(U)=\mathscr{E}(U)$ mit $df=\omega$ ergibt.
Für eine 1-Form
\[
\omega = \sum_{i=1}^nf_i(x)\, dx^i
\]
Zunächst ist
\[
H^*\omega
=
\sum_{i=1}^nf_i(tx)\, d(tx^i)
=
\sum_{i=1}^nf_i(tx) (x_i\, dt + t\, dx^i).
\]
Darauf muss jetz die Operation $\pi_*$ angewendet werden.
Diese ergibt aber nichtverschwindende Resultat nur auf Termen, in
denen $dt$ vorkommt.
Daher ist
\[
\pi_*H^*\omega
=
\int_0^1
\sum_{i=1}^n
f_i(tx) x^i\, dt
=
\int_0^1
\sum_{i=1}^n
f_i(\gamma_x(t)) \dot{x}^i(t)\, dt
=
\int_{\gamma_x}
\omega.
\]
Die von der Abbildung $J$ produzierte Funktion ist also im Falle
einer 1-Form gerade das Wegintegral über einen Weg vom Nullpunkt zum
Punkt $x$, wie in der ursprünglichen Konstruktion in
Kapitel~\ref{chapter:kurvenintegral}.
