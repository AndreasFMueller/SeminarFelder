%
% 1_herleitung.tex -- Herleitung der Methode
%
% (c) 2025 Roman Cvijanovic & Nicola Dall'Acqua, Hochschule Rapperswil
%
% !TEX root = ../../buch.tex
% !TEX encoding = UTF-8
%

\section{Herleitung der Methode\label{neuronal:section:herleitung}}
\kopfrechts{Herleitung der Methode}

Im Folgenden wird die Methode zum Lösen von Feldgleichungen mittels eines neuronalen Netzes theoretisch hergeleitet.
Dazu wird zunächst eine generelle Form für Feldgleichungen bzw. partielle Differentialgleichungen benötigt.
Die generelle Form einer Feldgleichung ist
\begin{equation}
\mathcal{D}(\varphi(x, t)) = 0 \qquad x \in \Omega, \quad t \in [0,T]
\label{neuronal:generelle_feldgleichung}
\end{equation}
mit der Randbedingung
\begin{equation}
\varphi(x, t) = 0 \qquad x \in \partial \Omega, \quad t \in [0,T]
\end{equation}
und den Anfangsbedingungen
\begin{equation}
    \begin{aligned}
        \varphi(x, t = 0) &= f(x) \qquad x \in \Omega \\
        \partial_t \varphi(x, t = 0) &= g(x) \qquad x \in \Omega.
    \end{aligned}
\end{equation}
Wobei:
\begin{itemize}
    \item $\varphi(x, t)$ das gesuchte Feld ist,
    \item $\mathcal{D}$ ein beliebiger Differentialoperator auf $\varphi$ ist,
    \item $f(x)$ und $g(x)$ bekannte Funktionen für die Anfangsbedingungen sind,
    \item $\Omega$ der Bereich des Feldes ist,
    \item $\partial \Omega$ der Rand des Feldes ist,
    \item $[0,T]$ das Zeitintervall des Feldes ist.
\end{itemize}
Als Beispiel für den Differentialoperator $\mathcal{D}$, dieser kann
\begin{equation*}
    \mathcal{D}(\varphi(x, y, t)) = \frac{\partial^2 \varphi}{\partial t^2} - c^2 \left( \frac{\partial^2 \varphi}{\partial x^2} + \frac{\partial^2 \varphi}{\partial y^2} \right)
\end{equation*}
sein. Setzt man das in die Gleichung \eqref{neuronal:generelle_feldgleichung} ein, entspricht diese der Wellengleichung in zwei Dimensionen.

Das Ziel ist es, die Lösung $\varphi(x, t)$ mit einem neuronalen Netzwerk $\hat{\varphi}(x, t; \vartheta)$ zu approximieren.
Das Netzwerk besitzt einen Vektor \( \vartheta \in \mathbb{R}^n \) der \emph{trainierbaren Parameter}.
Diese sollen so gewählt werden, dass die gesuchte Funktion $\varphi(x, t)$ durch das neuronale Netzwerk $\hat{\varphi}(x, t; \vartheta)$ approximiert wird.


\subsection{Aufbau neuronale Netzwerke}\label{neuronal:subsection:struktur_nn}
Nachfolgend wird beschrieben, was neuronale Netzwerke sind und wie diese aufgebaut sind.
Grundsätzlich sind neuronale Netzwerke Kompositionen von mehreren Teilfunktionen
\begin{equation}
    \hat{\varphi}(x, t; \vartheta) = f_j(\ldots(f_i(\ldots(f_1(x, y, t))))) = f_j \circ \ldots \circ f_i \ldots \circ f_1(x, t).
    \label{neuronal:nn_ausformuliert}
\end{equation}
Jede Teilfunktion \( f_i \) besteht aus einer affinen Transformation, gefolgt von einer nicht-linearen Aktivierungsfunktion \( g_i \)
\begin{align*}
    f_i\colon \mathbb{R}^q & \longrightarrow\mathbb{R}^p \\[-1ex]
    v & \longmapsto g_i(A_iv + b_i)
\end{align*}
mit \( v \in \mathbb{R}^q, A_i \in \mathbb{R}^{p \times q}, b_i \in \mathbb{R}^p \). 
Die Elemente aller \( A_i \) und \( b_i \) bilden den Vektor \( \vartheta \) der \emph{trainierbaren Parameter} des Netzwerks.
Für \( g_i \) gibt es viele Möglichkeiten, z.B. den hyperbolischen Tangens.
$g_i$ wird einzeln auf jedes Element des Resultats der affinen Transformation angewendet.
Welche Funktion verwendet wird hängt stark davon ab, was approximiert werden soll.

Die Definitions- und Wertebereiche der Teilfunktionen \( f_i \) sind mehr oder weniger frei wählbar.
Damit es mit den Dimensionen aufgeht, muss jeweils der Wertebereich von \( f_i \) gleich dem Definitionsbereich von \( f_{i+1} \) sein.
Zudem ist die Wahl der Anzahl Teilfunktionen nicht strikt vorgegeben.
Die einzigen strikten Vorgaben sind der Definitionsbereich der ersten Teilfunktion \( f_1 \) und der Wertebereich der letzten Teilfunktion \( f_k \).
Diese müssen \( \mathbb{R}^2 \) bzw. \( \mathbb{R} \) sein, damit das Netzwerk die gleichen Bereiche wie die Lösung der Feldgleichung
\begin{align*}
    \varphi\colon \mathbb{R}^2 & \longrightarrow\mathbb{R}
\end{align*}
hat.
Grundsätzlich gilt, je komplizierter die Funktion, die approximiert wird, desto grösser muss das neuronale Netzwerk sein.

Im Abschnitt \ref{neuronal:section:rechenbeispiel} werden konkrete Definitionen für neuronale Netzwerke zur Lösung der Wellengleichung und Burgers-Gleichung beschrieben.
Der Source-Code dieser Netzwerke ist im Github Repository des Seminars abgelegt \cite{neuronal:github_source_code}.

Nachfolgend ein kurzes Beispiel wie ein neuronales Netzwerk mit zwei Teilfunktionen mit der Python-Bibliothek PyTorch implementiert wird:
\begin{lstlisting}
# Definition des Netzwerks
t1 = nn.Linear(2, 10) # Dimension Input: R^2, Dimension Output: R^10
t2 = nn.Linear(10, 1)
activation = nn.Tanh()

# Auswerten an einem gegebenen Input x
temp = activation(t1(x))
out = activation(t2(x))
\end{lstlisting}

\subsection{Formulierung als Optimierungsproblem}\label{neuronal:subsection:optimierungsproblem}
In diesem Abschnitt geht es um die Wahl der \emph{trainierbaren Parameter} $\vartheta$ des Netzwerks.
Die Wahl von $\vartheta$ ist im Wesentlichen ein Minimierungsproblem.
Die Idee dabei ist, dass man eine Funktion \( L(\vartheta) \) findet, welche den Approximationsfehler des Netzwerks misst.
Anschliessend wird $L(\vartheta)$ -- bzw. der Approximationsfehler -- minimiert.
Das $\vartheta$ am Minimum ist dann geeignet für die Approximation.

\( L \) wird aus der Feldgleichung und den Bedingungen aufgebaut. Dazu müssen diese zunächst etwas umgeformt werden.
In allen Gleichungen, muss zuerst alles auf eine Seite (wo dies noch nicht bereits der Fall ist), anschliessend wird quadriert.
Für die Feldgleichung ergibt dies
\begin{equation}
    \left(\mathcal{D}(\varphi(x, t))\right)^2 = 0 \qquad x \in \Omega, \quad t \in [0,T].
    \label{neuronal:feldgleichung_umformuliert}
\end{equation}
Macht man das gleiche mit den Anfangs- und Randbedingungen, erhält man
\begin{equation}
    \begin{aligned}
        \left(f(x) - \varphi(x, t = 0)\right)^2 = 0 \qquad x \in \Omega\\
        \left(g(x) - \partial_t \varphi(x, t = 0)\right)^2 = 0 \qquad x \in \Omega
    \end{aligned}
    \label{neuronal:anfangsbedingung_umformuliert}
\end{equation}
und
\begin{equation}
    \begin{aligned}
        \left(\varphi(x, t)\right)^2 &= 0 \qquad x \in \partial \Omega, \quad t \in [0,T].
    \end{aligned}
    \label{neuronal:randbedingung_umformuliert}
\end{equation}
Als nächstes wird das neuronale Netzwerk $\hat{\varphi}$ für $\varphi$ substituiert
\begin{equation}
    \left(\mathcal{D}(\hat{\varphi}(x, t; \vartheta))\right)^2 \qquad x \in \Omega, \quad t \in [0,T]
    \label{neuronal:feldgleichung_umformuliert_netz}
\end{equation}
\begin{equation}
    \begin{aligned}
        \left(f(x) - \hat{\varphi}(x, t = 0; \vartheta)\right)^2 \qquad x \in \Omega\\
        \left(g(x) - \partial_t \hat{\varphi}(x, t = 0; \vartheta)\right)^2 \qquad x \in \Omega
    \end{aligned}
    \label{neuronal:anfangsbedingung_umformuliert_netz}
\end{equation}
\begin{equation}
    \begin{aligned}
        \left(\hat{\varphi}(x, t; \vartheta)\right)^2 \qquad x \in \partial \Omega, \quad t \in [0,T].
    \end{aligned}
    \label{neuronal:randbedingung_umformuliert_netz}
\end{equation}
Ziel ist es $\vartheta$ so zu wählen, dass alle Terme möglichst gleich 0 sind.
Anders ausgedrückt soll $\vartheta$ so gewählt werden, dass die Terme minimal werden.

Zu beachten ist, dass die Terme mit dem gewählten $\vartheta$ für alle $x, t$ in den jeweiligen Bereichen minimal sein sollen.
Das bedeutet, bevor $L(\vartheta)$ definiert werden kann, müssen $x$ und $t$ diskretiert werden.

\subsection{Diskretierung}\label{neuronal:subsection:diskretierung}
Zur Diskretierung werden drei Datensätze benötigt
\begin{equation}
    \begin{aligned}
        F &= \{\, (x, t) \,|\, x \in \Omega \setminus \partial \Omega\,, t \in (0,T] \,\}\\
        A &= \{\, (x, t) \,|\, x \in \Omega \setminus \partial \Omega\,, t = 0 \,\}\\
        B &= \{\, (x, t) \,|\, x \in \partial \Omega\,, t \in [0, T] \,\}.
    \end{aligned}
\end{equation}
Jeder Datensatz besteht aus $k$ Punkten in den jeweiligen Bereichen.
Es gilt/gelten:
\begin{itemize}
    \item Die Feldgleichung für die Punkte in $F$
    \item Die Anfangsbedingungen für die Punkte in $A$
    \item Die Randbedingungen für die Punkte in $B$
\end{itemize}
Nun werden die Terme \eqref{neuronal:feldgleichung_umformuliert_netz}, \eqref{neuronal:anfangsbedingung_umformuliert_netz}, \eqref{neuronal:randbedingung_umformuliert_netz} über die zugehörigen Datensätze summiert und gemittelt
\begin{equation}
    \frac{1}{k} \sum_{F}^{} \left(\mathcal{D}(\hat{\varphi}(x_i, t_i; \vartheta))\right)^2
    \label{neuronal:feldgleichung_umformuliert_netz_disk}
\end{equation}
\begin{equation}
    \begin{aligned}
        \frac{1}{k} \sum_{A}^{} \left(f(x_i) - \hat{\varphi}(x_i, t_i = 0; \vartheta)\right)^2\\
        \frac{1}{k} \sum_{A}^{} \left(g(x_i) - \partial_t \hat{\varphi}(x_i, t_i = 0; \vartheta)\right)^2
    \end{aligned}
    \label{neuronal:anfangsbedingung_umformuliert_netz_disk}
\end{equation}
\begin{equation}
    \begin{aligned}
        \frac{1}{k} \sum_{B}^{} \left(\mathcal{B}(\hat{\varphi}(x_i, t_i; \vartheta))\right)^2 &.
    \end{aligned}
    \label{neuronal:randbedingung_umformuliert_netz_disk}
\end{equation}
Diese Terme hängen nur noch von $\vartheta$ ab und sollen nach wie vor möglichst gleich 0 sein.
Wie im vorherigen Abschnitt \ref{neuronal:subsection:optimierungsproblem} beschrieben, soll eine Funktion $L(\vartheta)$ gefunden/definiert werden, welche den Approximationsfehler misst.
Addiert man die linken Seiten der obigen Terme, kann damit \( L \) als
\begin{equation}
    \begin{aligned}
        L(\vartheta) =\quad &\frac{1}{k} \sum_{F}^{} \left(\mathcal{D}[\hat{\varphi}(x_i, t_i; \vartheta)]\right)^2\\
        + &\frac{1}{k} \sum_{A}^{} \left(\left(f(x_i) - \hat{\varphi}(x_i, t_i = 0; \vartheta)\right)^2
        + \left(g(x_i) - \partial_t \hat{\varphi}(x_i, t_i = 0; \vartheta)\right)^2\right)\\
        + &\frac{1}{k} \sum_{B}^{} \left(\mathcal{B}[\hat{\varphi}](x_i, t_i; \vartheta)\right)^2
    \end{aligned}
    \label{neuronal:optimierung}
\end{equation}
definiert werden.
Für jede der drei Summen in \( L \) gilt:
\begin{itemize}
    \item Je genauer die Approximation des Netzwerks, desto näher bei 0
    \item Ist die Approximation perfekt (also \( \hat{\varphi} = \varphi \)) ist die Summe gleich 0
\end{itemize}
Dies bedeutet, je näher \( L \) bei 0 ist, desto besser ist die Approximation des Netzwerks.
$L$ ist daher tatsächlich ein Mass für den Approximationsfehler des Netzwerks.
Genauer gesagt, ist $L$ der mittlere Fehler über alle Datenpunkte der Diskretierung.

Die Wahl der Parameter des neuronalen Netzwerks ist nun ein Minimierungsproblem.
\begin{aufgabe}
    Minimiere $L(\vartheta)$, das $\vartheta$ am Minimum ist geeignet für die Approximation.
\end{aufgabe}

\subsection{Lösen des Minimierungsproblem}\label{neuronal:subsection:lösen_optimierungsproblem}
\( L \) lässt sich aus zwei Gründen nicht analytisch minimieren:
\begin{enumerate}
    \item \( L \) hängt von \( \vartheta \in \mathbb{R}^n \) ab. 
    Es müssten also alle \( n \) partiellen Ableitungen berechnet und nullgesetzt werden. 
    Da \( n \) eine sehr grosse Zahl ist, lässt sich das resultierende Gleichungssystem kaum lösen.
    \item Zudem würde das Lösen dieses Gleichungssystem voraussetzen, dass man die Feldgleichung löst, da diese in $L$ vorkommt.
\end{enumerate}
Das bedeutet, dass stattdessen ein numerischer Algorithmus verwendet werden muss.

\begin{aufgabe}
    Algorithmus (Gradientabstieg)
    \begin{enumerate}
        \item Initialisiere \( \vartheta_1 \) mit Anfangswerten.
        \item \textbf{Loop} von \( i = 1 \) bis \( i = m - 1 \):
        \begin{itemize}
            \item Berechne neue Parameterwerte: \( \vartheta_{i+1} = \vartheta_i - \varepsilon \nabla_\vartheta L\left(\vartheta_i\right) \). (Erklärung unten)
        \end{itemize}
        \item Gebe die Parameter \( \vartheta_m \) zurück.
    \end{enumerate}
    \label{neuronal:gradient_descent}
\end{aufgabe}

Die Anzahl Schleifendurchläufe \( m \), bzw. das Abbruchskriterium des Algorithmus, hängt stark vom konkreten Problem ab, das gelöst wird.
Im Abschnitt \ref{neuronal:section:rechenbeispiel} wird beschrieben, wie dies bei der Wellengleichung und Burgers-Gleichung aussieht.

Nach dem letzten Schritt dieses Algorithmus ist das neuronale Netzwerk mit den Parametern \( \vartheta_m \) fertig trainiert.

\textbf{Als abschliessende Notiz:} Im Schritt 2 des Algorithmus werden die Parameterwerte neu berechnet.
Durch die verwendete Formel wird erreicht, dass \( L(\vartheta_{i+1}) \leq L(\vartheta_i) \) ist, d.h. der Fehler des Netzwerks nimmt mit jedem Schritt ab.
Dies ist das Optimierungsverfahren \emph{Gradient Descent}.

Das funktioniert, da der Gradient von \( L \) ausgewertet an \( \vartheta_i \) ein Vektor ist, der in die Richtung des stärksten Anstiegs auf \( L \), von \(\vartheta_i \) aus, weist.
Durch das Minus in der Formel geht man in die entgegen gesetzte Richtung, wo es auf \( L \) abwärts geht. 
Mit \( \varepsilon \) wird die ``Schrittgrösse'' gesteuert, um zu verhindern dass man über ein Minimum auf \( L \) ``springt''.

Dieser Algorithmus birgt ein gewisses Risiko. 
Es gibt keine Garantie dafür dass man damit das globale Minimum von \( L \) findet.
Da der Algorithmus auf \( L \) mit jedem Schritt ``abwärts'' geht, kann es sein das nur ein lokales Minimum gefunden wird.
Ist der Algorithmus einmal in der Nähe eines lokalen Minimum, kommt man von dort nicht mehr weg, da man dazu ``aufwärts'' gehen müsste.
Wenn \( L \) viele lokale Minima besitzt, ist es sogar sehr wahrscheinlich, dass der Algorithmus ein solches findet.
Dies ist aber nicht unbedingt problematisch.
Wenn \( L \) am gefundenen lokalen Minimum sehr nahe bei 0 ist, ist der Approximationsfehler des Netzwerks sehr klein.
Dass nicht das globale Minimum gefunden wurde, spielt keine Rolle, solange der Approximationsfehler in einem akzeptablen Bereich liegt.

Eine weitere Gefahr ist, dass der Gradient an allen Arten von Extrempunkten 0 ist, nicht nur an Minima.
Wenn der Algorithmus sich genau auf einem Extrempunkt befindet, kommt man von dort nicht mehr weg.
Jedoch ist es sehr unwahrscheinlich dass dies passiert, denn der Algorithmus müsste sich genau auf dem Extrempunkt befinden.
Ist dies nicht der Fall und der Algorithmus ist etwas ``neben'' dem Extrempunkt, ist dies bereits kein Problem mehr.
Denn dort ist der Gradient bereits nicht mehr 0 und da es bei allen Extrempunkten -- ausser Minima -- in mindestens eine Richtung abwärts geht, wird der Algorithmus sich von dort wegbewegen.


\subsection{Qualitätsbewertung}\label{neuronal:subsection:qualitaetsbewertung}
Zur Bewertung der Qualität der Approximation steht zunächst der Wert von $L(\vartheta)$ nach Abschluss des Optimierungsalgorithmus zur Verfügung.
Dies gibt Aufschluss über den mittleren Approximationsfehler bei den Datenpunkten aus der Diskretierung.

Eine weitere Möglichkeit ist es, je einen Teil der drei Datensätze aus \ref{neuronal:subsection:diskretierung} nicht im Optimierungsalgorithmus zu verwenden, bzw. vorher abzutrennen.
Anschliessend definiert man eine neue Funktion $L^1(\vartheta)$ analog zu \eqref{neuronal:optimierung}, mit dem Unterschied dass nun über die abgetrennten (Teil-)Datensätze summiert wird.
Da diese Funktion nie explizit vom Optimierungsalgorithmus minimiert wurde, ist sie ein Mass für den mittleren Approximationsfehler bei Datenpunkten, die nicht in der Diskretierung verwendet wurden.

Eine letzte Möglichkeit zur Bewertung der Qualität ist der direkte Vergleich mit Lösungen, welche durch andere Verfahren gefunden wurden.
Gibt es zum Beispiel eine analytische Lösung zur Feldgleichung oder hat man eine Lösung durch die Finite-Elemente-Methode erhalten, kann damit verglichen werden.
